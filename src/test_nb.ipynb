{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook for Confidence Regions Toolbox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (1.21.6)\n",
      "Requirement already satisfied: pandas in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (3.5.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from matplotlib) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: nilearn in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (0.10.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nilearn) (1.2.0)\n",
      "Requirement already satisfied: lxml in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nilearn) (4.9.2)\n",
      "Requirement already satisfied: nibabel>=3.2.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nilearn) (4.0.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nilearn) (1.21.6)\n",
      "Requirement already satisfied: packaging in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nilearn) (23.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nilearn) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.25.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nilearn) (2.30.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nilearn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nilearn) (1.7.3)\n",
      "Requirement already satisfied: setuptools in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nibabel>=3.2.0->nilearn) (39.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from pandas>=1.1.5->nilearn) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from requests>=2.25.0->nilearn) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from requests>=2.25.0->nilearn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from requests>=2.25.0->nilearn) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from requests>=2.25.0->nilearn) (2023.5.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from scikit-learn>=1.0.0->nilearn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.1.5->nilearn) (1.16.0)\n",
      "Requirement already satisfied: nibabel in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (4.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nibabel) (1.21.6)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nibabel) (23.1)\n",
      "Requirement already satisfied: setuptools in /home/tommaullin/Documents/ConfSets_Rehaul/.venv/lib/python3.7/site-packages (from nibabel) (39.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install nilearn\n",
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports from Confidence Regions Toolbox\n",
    "from generate import generate_CRs\n",
    "from bootstrap import bootstrap_resids\n",
    "from coverage import check_violations\n",
    "\n",
    "# Import supporting functions\n",
    "from lib.set_theory import *\n",
    "from lib.boundary import *\n",
    "\n",
    "# Import data generation\n",
    "from tests.generate_2d_data import *\n",
    "from tests.generate_ni_data import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of fields m\n",
    "m = 3\n",
    "\n",
    "# Get number of subjects\n",
    "nSub = 80\n",
    "\n",
    "# Get number of simulation realizations\n",
    "nReals = 100\n",
    "\n",
    "# Get number of bootstraps\n",
    "nBoot = 5000\n",
    "\n",
    "# Get Threshold\n",
    "c = 2\n",
    "\n",
    "# Get p values\n",
    "p = np.linspace(0,1,21)\n",
    "\n",
    "# Get the number of p-values we're looking at\n",
    "nPvals = len(p)\n",
    "\n",
    "# Get Tau\n",
    "tau = 1/np.sqrt(nSub)\n",
    "\n",
    "# Dimensions of simulated data\n",
    "data_dim = np.array([nSub, 100,100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some circular signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Mus\n",
    "# ---------------------------------------------------------------\n",
    "# Create empty specifications\n",
    "mu_specs = {}\n",
    "\n",
    "# Loop through mus, adding each field in turn\n",
    "for i in np.arange(m):\n",
    "\n",
    "    # New empty dict\n",
    "    mu_specs['mu'+str(i+1)]={}\n",
    "\n",
    "    # Mu type\n",
    "    mu_specs['mu'+str(i+1)]['type'] = 'circle2D' \n",
    "\n",
    "    # Mu FWHM\n",
    "    mu_specs['mu'+str(i+1)]['fwhm'] = np.array([5,5])\n",
    "\n",
    "    # Mu r\n",
    "    mu_specs['mu'+str(i+1)]['r'] = 40\n",
    "\n",
    "    # Mu magnitude\n",
    "    mu_specs['mu'+str(i+1)]['mag'] = 3\n",
    "\n",
    "    # Get some evenly spaced center points\n",
    "    centers = circle_points(np.array([25]),np.array([m]))\n",
    "\n",
    "    # Mu center\n",
    "    mu_specs['mu'+str(i+1)]['center'] = centers[i,:].astype(np.int)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Epsilons\n",
    "# ---------------------------------------------------------------\n",
    "# Create empty specifications\n",
    "noise_specs = {}\n",
    "\n",
    "# Loop through noises, adding each field in turn\n",
    "for i in np.arange(m):\n",
    "\n",
    "    # New empty dict\n",
    "    noise_specs['noise'+str(i+1)]={}\n",
    "\n",
    "    # Add FWHM\n",
    "    noise_specs['noise'+str(i+1)]['FWHM'] = np.array([0, 3, 3])\n",
    "\n",
    "    # Add type\n",
    "    noise_specs['noise'+str(i+1)]['type'] = 'homogen'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(m):\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # Data generation\n",
    "    # ----------------------------------------------------------------\n",
    "\n",
    "    # Obtain noise\n",
    "    noise = get_noise(noise_specs['noise'+str(i+1)], data_dim)\n",
    "\n",
    "    # Obtain mu\n",
    "    mu = get_mu(mu_specs['mu'+str(i+1)], data_dim)\n",
    "\n",
    "    # Create the data\n",
    "    data = mu + noise\n",
    "\n",
    "    # Save mus\n",
    "    if i == 0:\n",
    "        mus = np.array(mu)\n",
    "    else:\n",
    "        mus = np.concatenate((mus,mu),axis=0)\n",
    "\n",
    "    # Combine data\n",
    "    if i == 0:\n",
    "        datas = np.array(data.reshape(1,*(data.shape)))\n",
    "    else:\n",
    "        datas = np.concatenate((datas,data.reshape(1,*(data.shape))),axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Some Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for the \"5th\" subject\n",
    "plt.imshow(np.mean(datas,axis=1)[2,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Confidence Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "out_dir = '/home/tommaullin/Documents'\n",
    "\n",
    "# Generate Confidence Regions\n",
    "FcHat_minus, FcHat_plus, FcHat, a = generate_CRs(datas, c, p, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 20\n",
    "\n",
    "print(a[i],p[i])\n",
    "plt.imshow(1*FcHat_plus[i,:,:]+1*FcHat+1*FcHat_minus[i,:,:])\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[i])\n",
    "plt.imshow(1*FcHat_plus[i,:,:]-1*FcHat_minus[i,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Fc\n",
    "Fc = mu > c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results\n",
    "results = check_violations(FcHat_plus, FcHat_minus, datas, mus, c, tau, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Coverage over Repeated Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Set the number of repetitions\n",
    "nReps = 1000\n",
    "\n",
    "# Loop through the repetitions\n",
    "for j in np.arange(nReps):\n",
    "    print(j)\n",
    "    \n",
    "    # Time data generation\n",
    "    start = time.time()\n",
    "\n",
    "    for i in np.arange(m):\n",
    "        # Obtain noise\n",
    "        noise = get_noise(noise_specs['noise'+str(i+1)], data_dim)\n",
    "\n",
    "        # Obtain mu\n",
    "        mu = get_mu(mu_specs['mu'+str(i+1)], data_dim)\n",
    "\n",
    "        # Create the data\n",
    "        data = mu + noise\n",
    "\n",
    "        # Save mus\n",
    "        if i == 0:\n",
    "            mus = np.array(mu)\n",
    "        else:\n",
    "            mus = np.concatenate((mus,mu),axis=0)\n",
    "\n",
    "        # Combine data\n",
    "        if i == 0:\n",
    "            datas = np.array(data.reshape(1,*(data.shape)))\n",
    "        else:\n",
    "            datas = np.concatenate((datas,data.reshape(1,*(data.shape))),axis=0)\n",
    "    \n",
    "    # Time data generation\n",
    "    end = time.time()\n",
    "    #print(end - start)\n",
    "\n",
    "    # Time confidence region generation\n",
    "    start = time.time()\n",
    "\n",
    "    # Generate Confidence Regions\n",
    "    FcHat_minus, FcHat_plus, FcHat, a = generate_CRs(datas, c, p, out_dir)\n",
    "\n",
    "    # Time confidence region generation\n",
    "    end = time.time()\n",
    "    #print(end - start)\n",
    "\n",
    "    # Time violation checking\n",
    "    start = time.time()\n",
    "\n",
    "    # Get the results\n",
    "    results = check_violations(FcHat_plus, FcHat_minus, datas, mus, c, tau, a)\n",
    "\n",
    "    # Time violation checking\n",
    "    end = time.time()\n",
    "    #print(end - start)\n",
    "\n",
    "    #print(results)\n",
    "    # Average the results\n",
    "    if j == 0:\n",
    "        avg_results = np.array(results[0])\n",
    "    else:\n",
    "        # Concatenate the results\n",
    "        concat_results = np.concatenate((avg_results.reshape(1,np.prod(avg_results.shape)),\n",
    "                                        results[0].reshape(1,np.prod(avg_results.shape))),axis=0)\n",
    "        # Avergae the results\n",
    "        avg_results = np.mean(concat_results,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average results against p\n",
    "plt.plot(p,avg_results)\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('Average number of violations')\n",
    "plt.title('Average number of violations against p')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuroImaging Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate some test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 120, 120, 3, 1)\n",
      "(100, 100, 100, 3)\n",
      "(100, 100)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 10000 into shape (1000000,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18082/742716057.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Generate some test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ConfSets_Rehaul/src/tests/generate_ni_data.py\u001b[0m in \u001b[0;36mgenerate_data\u001b[0;34m(n, p, OutDir, dim, mask_type)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Save beta to nifti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0maddBlockToNifti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutDir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".nii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolInd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morigdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# -----------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ConfSets_Rehaul/src/lib/fileio.py\u001b[0m in \u001b[0;36maddBlockToNifti\u001b[0;34m(fname, block, blockInds, dim, volInd, aff, hdr)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# Add block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblockInds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblockInds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;31m# Put in the volume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10000 into shape (1000000,1)"
     ]
    }
   ],
   "source": [
    "# Parameters for data generation\n",
    "n = 30\n",
    "p = 3\n",
    "out_dir = '/home/tommaullin/Documents/ConfSets_Rehaul/'\n",
    "\n",
    "# Generate some test data\n",
    "generate_data(n,p,out_dir)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean and standard deviation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the filenames for the Y files from the text file\n",
    "\n",
    "regression(yfiles, X, out_dir, chunk_size=20)\n",
    "\n",
    "read_images_mean_std(fnames, mean_zero=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.ones((100,100))\n",
    "\n",
    "coords = np.where(img)\n",
    "\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = np.array([10,50,60])\n",
    "r = 8\n",
    "dim = np.array([100,100,100])\n",
    "\n",
    "\n",
    "# Create an ogrid\n",
    "ogrid = np.meshgrid(*[np.arange(d) for d in dim], indexing='ij')\n",
    "\n",
    "# Calculate distance from the center\n",
    "distance = sum((g - c)**2 for g, c in zip(ogrid, center))\n",
    "\n",
    "# Create the sphere\n",
    "sphere = np.array(np.sqrt(distance) < r, dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a slice of the sphere\n",
    "plt.imshow(sphere[11,:,:])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
