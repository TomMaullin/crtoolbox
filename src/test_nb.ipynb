{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook for Confidence Regions Toolbox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install nilearn\n",
    "%pip install nibabel\n",
    "%pip install dask\n",
    "%pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports from Confidence Regions Toolbox\n",
    "from generate import generate_CRs\n",
    "from coverage import check_violations\n",
    "\n",
    "# Import supporting functions\n",
    "from lib.set_theory import *\n",
    "from lib.boundary import *\n",
    "from lib.regression import *\n",
    "\n",
    "# Import data generation\n",
    "from tests.generate_2d_data import *\n",
    "from tests.generate_ni_data import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of fields m\n",
    "m = 3\n",
    "\n",
    "# Get number of subjects\n",
    "nSub = 80\n",
    "\n",
    "# Get number of simulation realizations\n",
    "nReals = 100\n",
    "\n",
    "# Get number of bootstraps\n",
    "nBoot = 5000\n",
    "\n",
    "# Get Threshold\n",
    "c = 2\n",
    "\n",
    "# Get p values\n",
    "p = np.linspace(0,1,21)\n",
    "\n",
    "# Get the number of p-values we're looking at\n",
    "nPvals = len(p)\n",
    "\n",
    "# Get Tau\n",
    "tau = 1/np.sqrt(nSub)\n",
    "\n",
    "# Dimensions of simulated data\n",
    "data_dim = np.array([nSub, 100,100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some circular signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Mus\n",
    "# ---------------------------------------------------------------\n",
    "# Create empty specifications\n",
    "mu_specs = {}\n",
    "\n",
    "# Loop through mus, adding each field in turn\n",
    "for i in np.arange(m):\n",
    "\n",
    "    # New empty dict\n",
    "    mu_specs['mu'+str(i+1)]={}\n",
    "\n",
    "    # Mu type\n",
    "    mu_specs['mu'+str(i+1)]['type'] = 'circle2D' \n",
    "\n",
    "    # Mu FWHM\n",
    "    mu_specs['mu'+str(i+1)]['fwhm'] = np.array([5,5])\n",
    "\n",
    "    # Mu r\n",
    "    mu_specs['mu'+str(i+1)]['r'] = 40\n",
    "\n",
    "    # Mu magnitude\n",
    "    mu_specs['mu'+str(i+1)]['mag'] = 3\n",
    "\n",
    "    # Get some evenly spaced center points\n",
    "    centers = circle_points(np.array([25]),np.array([m]))\n",
    "\n",
    "    # Mu center\n",
    "    mu_specs['mu'+str(i+1)]['center'] = centers[i,:].astype(np.int)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Epsilons\n",
    "# ---------------------------------------------------------------\n",
    "# Create empty specifications\n",
    "noise_specs = {}\n",
    "\n",
    "# Loop through noises, adding each field in turn\n",
    "for i in np.arange(m):\n",
    "\n",
    "    # New empty dict\n",
    "    noise_specs['noise'+str(i+1)]={}\n",
    "\n",
    "    # Add FWHM\n",
    "    noise_specs['noise'+str(i+1)]['FWHM'] = np.array([0, 3, 3])\n",
    "\n",
    "    # Add type\n",
    "    noise_specs['noise'+str(i+1)]['type'] = 'homogen'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(m):\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # Data generation\n",
    "    # ----------------------------------------------------------------\n",
    "\n",
    "    # Obtain noise\n",
    "    noise = get_noise(noise_specs['noise'+str(i+1)], data_dim)\n",
    "\n",
    "    # Obtain mu\n",
    "    mu = get_mu(mu_specs['mu'+str(i+1)], data_dim)\n",
    "\n",
    "    # Create the data\n",
    "    data = mu + noise\n",
    "\n",
    "    # Save mus\n",
    "    if i == 0:\n",
    "        mus = np.array(mu)\n",
    "    else:\n",
    "        mus = np.concatenate((mus,mu),axis=0)\n",
    "\n",
    "    # Combine data\n",
    "    if i == 0:\n",
    "        datas = np.array(data.reshape(1,*(data.shape)))\n",
    "    else:\n",
    "        datas = np.concatenate((datas,data.reshape(1,*(data.shape))),axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Some Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for the \"5th\" subject\n",
    "plt.imshow(np.mean(datas,axis=1)[2,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Confidence Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "out_dir = '/home/tommaullin/Documents'\n",
    "\n",
    "# Generate Confidence Regions\n",
    "FcHat_minus, FcHat_plus, FcHat, a = generate_CRs(datas, c, p, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 20\n",
    "\n",
    "print(a[i],p[i])\n",
    "plt.imshow(1*FcHat_plus[i,:,:]+1*FcHat+1*FcHat_minus[i,:,:])\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[i])\n",
    "plt.imshow(1*FcHat_plus[i,:,:]-1*FcHat_minus[i,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Fc\n",
    "Fc = mu > c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results\n",
    "results = check_violations(FcHat_plus, FcHat_minus, datas, mus, c, tau, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Coverage over Repeated Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Set the number of repetitions\n",
    "nReps = 1000\n",
    "\n",
    "# Loop through the repetitions\n",
    "for j in np.arange(nReps):\n",
    "    print(j)\n",
    "    \n",
    "    # Time data generation\n",
    "    start = time.time()\n",
    "\n",
    "    for i in np.arange(m):\n",
    "        # Obtain noise\n",
    "        noise = get_noise(noise_specs['noise'+str(i+1)], data_dim)\n",
    "\n",
    "        # Obtain mu\n",
    "        mu = get_mu(mu_specs['mu'+str(i+1)], data_dim)\n",
    "\n",
    "        # Create the data\n",
    "        data = mu + noise\n",
    "\n",
    "        # Save mus\n",
    "        if i == 0:\n",
    "            mus = np.array(mu)\n",
    "        else:\n",
    "            mus = np.concatenate((mus,mu),axis=0)\n",
    "\n",
    "        # Combine data\n",
    "        if i == 0:\n",
    "            datas = np.array(data.reshape(1,*(data.shape)))\n",
    "        else:\n",
    "            datas = np.concatenate((datas,data.reshape(1,*(data.shape))),axis=0)\n",
    "    \n",
    "    # Time data generation\n",
    "    end = time.time()\n",
    "    #print(end - start)\n",
    "\n",
    "    # Time confidence region generation\n",
    "    start = time.time()\n",
    "\n",
    "    # Generate Confidence Regions\n",
    "    FcHat_minus, FcHat_plus, FcHat, a = generate_CRs(datas, c, p, out_dir)\n",
    "\n",
    "    # Time confidence region generation\n",
    "    end = time.time()\n",
    "    #print(end - start)\n",
    "\n",
    "    # Time violation checking\n",
    "    start = time.time()\n",
    "\n",
    "    # Get the results\n",
    "    results = check_violations(FcHat_plus, FcHat_minus, datas, mus, c, tau, a)\n",
    "\n",
    "    # Time violation checking\n",
    "    end = time.time()\n",
    "    #print(end - start)\n",
    "\n",
    "    #print(results)\n",
    "    # Average the results\n",
    "    if j == 0:\n",
    "        avg_results = np.array(results[0])\n",
    "    else:\n",
    "        # Concatenate the results\n",
    "        concat_results = np.concatenate((avg_results.reshape(1,np.prod(avg_results.shape)),\n",
    "                                        results[0].reshape(1,np.prod(avg_results.shape))),axis=0)\n",
    "        # Avergae the results\n",
    "        avg_results = np.mean(concat_results,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average results against p\n",
    "plt.plot(p,avg_results)\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('Average number of violations')\n",
    "plt.title('Average number of violations against p')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuroImaging Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate some test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for data generation\n",
    "n = 30\n",
    "p = 3\n",
    "out_dir = '/home/tommaullin/Documents/ConfSets_Rehaul/'\n",
    "\n",
    "# Generate some test data\n",
    "y_files, beta_files, X = generate_data(n, p, out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean and standard deviation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the estimated betahat, sigmahat and residuals\n",
    "betahat_files, var_betahat_files, resid_files = regression(y_files, X, out_dir, chunk_size=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the first $\\hat{\\beta}$ as our signal, $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get muhat and sigmahat\n",
    "muhat_file = betahat_files[0]\n",
    "sigmahat_file = var_betahat_files[0]\n",
    "\n",
    "# Threshold c\n",
    "c = 2\n",
    "\n",
    "# Get p values\n",
    "p = np.linspace(0,1,21)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to generate some CRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CRs\n",
    "FcHat_minus, FcHat_plus, FcHat, a_estBdry = generate_CRs(muhat_file, sigmahat_file, resid_files, c, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 20\n",
    "slice = 51\n",
    "\n",
    "print(a_estBdry[i],p[i])\n",
    "plt.imshow(1*FcHat_plus[i,slice,:,:]+1*FcHat[slice,:,:]+1*FcHat_minus[i,slice,:,:])\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in muhat and make an image of it\n",
    "muhat = nib.load(muhat_file).get_fdata()\n",
    "sigmahat = nib.load(sigmahat_file).get_fdata()\n",
    "\n",
    "# Make image\n",
    "plt.imshow((muhat[slice,:,:]-c)/sigmahat[slice,:,:])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make image\n",
    "plt.imshow(muhat[slice,:,:])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2])\n",
    "\n",
    "t1 = time.time()\n",
    "np.array2string(a)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile([1,1],100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time1 = 0\n",
    "total_time2 = 0\n",
    "\n",
    "for i in np.arange(10000):\n",
    "\n",
    "    t1 = time.time()\n",
    "    (2*np.random.randint(0,2,(100,100),dtype=\"int8\")-1).dtype\n",
    "    t2 = time.time()\n",
    "\n",
    "    total_time1 += t2-t1\n",
    "\n",
    "    t1 = time.time()\n",
    "    (2*np.random.randint(0,2,(100,100))-1).dtype\n",
    "    t2 = time.time()\n",
    "\n",
    "    total_time2 += t2-t1\n",
    "\n",
    "print(total_time1, total_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((2*np.random.randint(0,2,(100,100),dtype=\"int8\")-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.randint(0,2,(1,10,10),dtype=\"int8\")==1\n",
    "data = np.random.randn(10,10,10)\n",
    "\n",
    "\n",
    "print(np.sum(mask))\n",
    "\n",
    "# Return the elements of the data inside the mask, broadcasting the mask\n",
    "print(data[np.broadcast_to(mask, data.shape)])\n",
    "print(data[np.broadcast_to(mask, data.shape)].shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
