{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suprema Simulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pip Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dask\n",
    "!pip install crtoolbox\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install distributed\n",
    "!pip install pyblm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blm imports\n",
    "from pyblm.blm import _main as blm\n",
    "import yaml\n",
    "\n",
    "# Dask imports\n",
    "from dask.distributed import Client, as_completed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Import supporting functions\n",
    "from crtoolbox.lib.boundary import *\n",
    "from crtoolbox.lib.regression import *\n",
    "\n",
    "# Import bootstrap functions\n",
    "from crtoolbox.bootstrap import *\n",
    "\n",
    "# Import data generation\n",
    "from crtoolbox.tests.generate_2d_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output directory\n",
    "out_dir = '/well/nichols/users/inf852/sup_sim'\n",
    "\n",
    "# If output directory does not exist, create it\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up ground truth analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth directory\n",
    "gt_dir = os.path.join(out_dir, 'ground_truth')\n",
    "\n",
    "# If ground truth directory does not exist, create it\n",
    "if not os.path.exists(gt_dir):\n",
    "    os.makedirs(gt_dir)\n",
    "\n",
    "# Construct the inputs.yaml for the ground truth analysis with the following parameters:\n",
    "inputs = {\n",
    "    \"MAXMEM\": '2**34',\n",
    "    \"M_files\": \"/users/nichols/inf852/Biobank1_Mfiles_2021.txt\",\n",
    "    \"OutputCovB\": '0',\n",
    "    \"X\": \"/users/nichols/inf852/Biobank1_X_2021.csv\",\n",
    "    \"Y_files\": \"/users/nichols/inf852/Biobank1_Yfiles_2021.txt\",\n",
    "    \"analysis_mask\": \"/well/win/software/packages/fsl/5.0.11/data/standard/MNI152_T1_2mm_brain_mask.nii.gz\",\n",
    "    \"contrasts\": [\n",
    "        {\n",
    "            \"c1\": {\n",
    "                \"name\": \"Tcontrast1\",\n",
    "                \"vector\": '[1, 0, 0, 0, 0, 0]'\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"outdir\": gt_dir,\n",
    "    \"sim\": \"1\",\n",
    "}\n",
    "\n",
    "# Write the inputs.yaml file\n",
    "with open(os.path.join(gt_dir, 'inputs.yml'), 'w') as outfile:\n",
    "    yaml.dump(inputs, outfile, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run BLM analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ground truth analysis\n",
    "blm(os.path.join(gt_dir, 'inputs.yml'))\n",
    "\n",
    "# Wait until 'nb.txt' exists in the ground truth directory\n",
    "while not os.path.exists(os.path.join(gt_dir, 'nb.txt')):\n",
    "    pass\n",
    "\n",
    "# Wait until 'nb.txt' is removed from the ground truth directory\n",
    "while os.path.exists(os.path.join(gt_dir, 'nb.txt')):\n",
    "    pass\n",
    "\n",
    "# The analysis should now be complete. We can now define the ground truth mu and sigma files\n",
    "mu_file = os.path.join(gt_dir, 'blm_vox_beta.nii')\n",
    "\n",
    "# Load the mu file\n",
    "mu = nib.load(mu_file).get_fdata()\n",
    "\n",
    "# Make sure the mu file is 3D by removing any singleton dimensions\n",
    "mu = np.squeeze(mu[0, :, :, :])\n",
    "\n",
    "# Save the mu file back to blm_vox_beta.nii\n",
    "nib.save(nib.Nifti1Image(mu, np.eye(4)), mu_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 1000 Random n=100 Analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of simulation instances\n",
    "n_sim = 1#000\n",
    "\n",
    "# Set number of subjects\n",
    "n_sub = 1000\n",
    "\n",
    "# Threshold c=1% BOLD signal change\n",
    "c = 10\n",
    "\n",
    "# Loop over simulation instances\n",
    "for i in range(n_sim):\n",
    "\n",
    "    # Set the output directory for this simulation instance\n",
    "    sim_dir = os.path.join(out_dir, 'sim_{:04d}'.format(i))\n",
    "\n",
    "    # If the output directory does not exist, create it\n",
    "    if not os.path.exists(sim_dir): \n",
    "        os.makedirs(sim_dir)\n",
    "\n",
    "    # Randomly select n_sub subject indices between 0 and 2021\n",
    "    sub_idx = np.random.choice(2021, n_sub, replace=False)\n",
    "\n",
    "    # Construct the Y list file by taking the lines of Biobank1_Yfiles_2021.txt corresponding to the selected subject indices\n",
    "    with open(\"/users/nichols/inf852/Biobank1_Yfiles_2021.txt\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    with open(os.path.join(sim_dir, 'Yfiles.txt'), 'w') as f:\n",
    "        for idx in sub_idx:\n",
    "            f.write(lines[idx])\n",
    "\n",
    "    # Construct the M list file by taking the lines of Biobank1_Mfiles_2021.txt corresponding to the selected subject indices\n",
    "    with open(\"/users/nichols/inf852/Biobank1_Mfiles_2021.txt\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    with open(os.path.join(sim_dir, 'Mfiles.txt'), 'w') as f:\n",
    "        for idx in sub_idx:\n",
    "            f.write(lines[idx])\n",
    "\n",
    "    # Construct the X file by taking the lines of Biobank1_X_2021.csv corresponding to the selected subject indices\n",
    "    X = pd.read_csv(\"/users/nichols/inf852/Biobank1_X_2021.csv\", header=None)\n",
    "    X = X.iloc[sub_idx, :]\n",
    "    X.to_csv(os.path.join(sim_dir, 'X.csv'), header=False, index=False)\n",
    "\n",
    "\n",
    "    # Construct the inputs.yaml for this simulation instance with the following parameters:\n",
    "    inputs = {\n",
    "        \"MAXMEM\": '2**34',\n",
    "        \"M_files\": os.path.join(sim_dir, 'Mfiles.txt'),\n",
    "        \"OutputCovB\": '0',\n",
    "        \"X\": os.path.join(sim_dir, 'X.csv'),\n",
    "        \"Y_files\": os.path.join(sim_dir, 'Yfiles.txt'),\n",
    "        \"analysis_mask\": \"/well/win/software/packages/fsl/5.0.11/data/standard/MNI152_T1_2mm_brain_mask.nii.gz\",\n",
    "        \"contrasts\": [\n",
    "            {\n",
    "                \"c1\": {\n",
    "                    \"name\": \"Tcontrast1\",\n",
    "                    \"vector\": '[1, 0, 0, 0, 0, 0]'\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"outdir\": sim_dir,\n",
    "        \"sim\": \"1\",\n",
    "    }\n",
    "\n",
    "    # Write the inputs.yaml file\n",
    "    with open(os.path.join(sim_dir, 'inputs.yml'), 'w') as outfile:\n",
    "        yaml.dump(inputs, outfile, default_flow_style=False)\n",
    "\n",
    "    # Run the simulation instance\n",
    "    blm(os.path.join(sim_dir, 'inputs.yml'))\n",
    "\n",
    "    # Wait until 'nb.txt' exists in the simulation instance directory\n",
    "    while not os.path.exists(os.path.join(sim_dir, 'nb.txt')):\n",
    "        pass\n",
    "\n",
    "    # Wait until 'nb.txt' is removed from the simulation instance directory\n",
    "    while os.path.exists(os.path.join(sim_dir, 'nb.txt')):\n",
    "        pass\n",
    "\n",
    "    # The analysis should now be complete. We can now define the muhat and sigma files\n",
    "    betahat_file = os.path.join(gt_dir, 'blm_vox_beta.nii')\n",
    "\n",
    "    # Read the betahat file\n",
    "    betahat = nib.load(betahat_file).get_fdata()\n",
    "\n",
    "    # Loop through Y files and construct residuals\n",
    "    for j in range(n_sub):\n",
    "\n",
    "        # Load the Y file by reading its name from the Yfiles.txt file as the jth line\n",
    "        with open(os.path.join(sim_dir, 'Yfiles.txt')) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        Y_file = lines[j].strip()\n",
    "\n",
    "        # Load the Y file\n",
    "        Y = nib.load(Y_file).get_fdata()\n",
    "\n",
    "        # Compute the residuals\n",
    "        res = Y - X.reshape(X.shape + (1,1,1)) @ betahat_file # MARKER to fix\n",
    "\n",
    "        # Residual file name\n",
    "        res_fname = os.path.join(sim_dir, 'res_{:04d}.nii'.format(j))\n",
    "\n",
    "        # Save the residual\n",
    "        nib.save(nib.Nifti1Image(res, np.eye(4)), res_fname)\n",
    "                 \n",
    "        # Append the residual to the list of residuals\n",
    "        if j == 0:\n",
    "            res_fnames = [res_fname]\n",
    "        else:\n",
    "            res_fnames.append(res_fname)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
